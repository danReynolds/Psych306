# Hearing in the Environment

## Interaural Time Difference (ITD)

The difference in time between a sound arriving at one ear versus the other.

Can tell which side a sound is coming from based on which ear it hits first.

## Physiology of ITDs

The **Medial Superior Olives (MSOs)** are the first places in the auditory system where inputs from both ears converge. Firing rates of neurons in the MSOs increase in response to very brief time differences between inputs from the two ears of cats.

## Interaural Level Difference (ILD)

Sounds are more intense at the ear closer to the sound source because the head partially blocks the sound pressure wave from reaching the opposite ear.

So it isn't just that it takes longer to get to the ear on the other side, some of the sound waves are blocked by the near side, so that the other side receives less intense sound.

No ILD when facing 0 degrees, or 180.

The head blocks high frequency sounds much better than low frequency sounds. Our inability to locate low frequencies in space is the reason it does not matter where a room features its subwoofer.

Neurons sensitive to intensity differences between the ears are found in the **Lateral superior olives** which receive both excitatory and inhibitory inputs.

Excitatory inputs come from the ipsilateral, same side ear, while inhibitory inputs come from the contralateral ear. Makes sense, if right ear gets stuff, tells left what it doesn't know.

When the sound is more intense in one ear, the lateral superior olive for that side is excited, and the other side's is inhibited, making a noticeable intensity difference.

## Cones of Confusion

A region of positions in space where all sounds produce the same time and level intensity differences (ITD and ILD)s making the sound's location ambiguous.

## Pinna and Head Cues

Time and intensity differences are not the only cues for pinpointing the location of sound, the pinnae, the physical outer part of the ear, funnels some frequencies of sound more efficiently than others.

Therefore the intensity of each frequency varies slightly according to the direction of the sound. This variation is another localization cue.

Changes in elevation also effect the intensity of sound received by the ears, and the sum total of these intensity shifts is measured and combined to become the **directional transfer function (DTF)** for an individual.

**Directional Transfer Function (DTF)** = describes how the pinna, ear canal, head, and torso change the intensity of sounds with different frequencies that arrive at each ear from different locations in space.

You can simulate a DTF by creating music with multiple recording microphones, one on the left and one on the right for each ear, but they don't take into account the unique pinna and torso of a listener, so to make a perfect recording that preserves the location of emanating sound from a musical performance, you'd need a custom recording for a certain person.

## Auditory Distance Perception

The simplest cue for judging the distance of a sound source is the **relative intensity** of the sound.

But a softer sounding animal may be closer than the howl of a further away one.

Movement helps, since a far away sound wouldn't change much compared to a close one as you move around it.

The sound absorbing qualities of air dampen high frequency sounds more than low frequencies, so the farther away a sound is, the more you hear its lower frequencies.

Close thunder sounds like a crack, but those high frequency sounds are diminished further away, where thunder sounds like a boom.

Direct vs reverberant energy also effect the distance perception, talking to someone up close is all direct energy from them to your ear, but at a concert there is reverberant energy from the singer's voice bouncing off walls will take time and you cant discriminate near vs far that way.

## Complex Sounds: Harmonics

The lowest frequency of a harmonic spectrum is the **fundamental frequency**.

There is also energy at frequencies that are integer multiples of the fundamental frequency. The vocal cords may produce the greatest energy by creating a standing wave at 250Hz, but then less at 500Hz, 750, 100Hz, etc. these are each n-th harmonics.

The **missing fundamental** is the effect where if the fundamental frequency is removed from a  series of harmonics, the pitch that listeners hear corresponds to the fundamental frequency, even though it is not there.

All harmonics of a fundamental frequency have fluctuations in sound pressure at regular intervals corresponding to the fundamental frequency.

Their peaks align on the same intervals so other fundamental frequencies resemble the fundamental frequency.

## Timbre

The perceptual quality that differs between musical instruments, like a trombone versus a saxophone playing the same not at the same loudness is the **timbre**.

Timbre is defined as the quality of two sounds that differentiates them to the listener despite having the same pitch and loudness.

## Attack and Decay

The way a sound begins, its **attack** and ends, its **decay** is given special attention by our auditory system.

Music synthesizers had trouble mimicking the attack and decay of instruments.

## Auditory Scene Analysis

The distinction of auditory events or objects in the broader auditory environment is called **source segregation** or **auditory scene analysis**.

## Spatial, Spectral and Temporal Segregation

1. Spatial: Can separate sounds based on their location, and if they're moving sound sources they're easier to discern from stationary sounds.

2. Spectral: Sounds with the same pitch or similar pitches are more likely to be treated as coming from the same source and be segregated from other sounds. Sounds that are perceived to come from the same source get segregated together into separate streams of audio objects.
This coincides with Gestalt's principle of similarity.

## Grouping by Timbre

Streams with notes of similar timbres are another example of grouping by similarity.

This ability allows listeners to pick out a trombone from the full sound of the band.

## Grouping by Onset

Sound components that begin at the same time, or nearly the same time, such as the harmonics of a music or speech, will also tend to be heard as coming from the same source.

Notes are more easily distinguished from one another if the onset of one differs from the other by 30ms.

Musicians playing the same note of different instruments at the same time will have slightly different onsets and this staggered start helps listeners pick out individual instruments. Grouping by onset is consistent with the Gestalt principle of common fate.

## When Sounds become Familiar

You become familiar with sounds and can pick them out better than others, like your name.

## Continuity and Restoration Effects

If there is a brief interruption in a sound you can probably "hear through" the interruption. This effect is consistent with the Gestalt principle of good continuation.

Auditory restoration is analogous to the way that the visual system fills in the portions of an image that is occluded.

## Restoration of Complex Sounds

Listening to complex sounds like real sentences allow listeners to use more than just auditory processing to fill in missing info. Will restore what makes sense contextually based on the sentence, so not just sound but also context.

## Auditory Attention

**Acoustic startle reflex** = very rapid motor response to a sudden sound. Very few neurons are involved in the basic startle reflex, which can also be affected by emotional state.

A loud sound startles us.

**Inattentional deafness** = Effects of attending to a particular sound can be so strong that we completely miss out on hearing other sounds.

Helps with hearing someone in a crowd if you can shut out the sounds from the crowd and focus on them.
